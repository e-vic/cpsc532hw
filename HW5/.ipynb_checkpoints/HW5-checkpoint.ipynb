{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-c907c3321834>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mNormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNormal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dist' is not defined"
     ]
    }
   ],
   "source": [
    "# Primitive functions\n",
    "import torch\n",
    "import torch.distributions as dist\n",
    "\n",
    "class Normal(dist.Normal):\n",
    "    \n",
    "    def __init__(self, alpha, loc, scale):\n",
    "        \n",
    "        if scale > 20.:\n",
    "            self.optim_scale = scale.clone().detach().requires_grad_()\n",
    "        else:\n",
    "            self.optim_scale = torch.log(torch.exp(scale) - 1).clone().detach().requires_grad_()\n",
    "        \n",
    "        \n",
    "        super().__init__(loc, torch.nn.functional.softplus(self.optim_scale))\n",
    "    \n",
    "    def Parameters(self):\n",
    "        \"\"\"Return a list of parameters for the distribution\"\"\"\n",
    "        return [self.loc, self.optim_scale]\n",
    "        \n",
    "    def make_copy_with_grads(self):\n",
    "        \"\"\"\n",
    "        Return a copy  of the distribution, with parameters that require_grad\n",
    "        \"\"\"\n",
    "        \n",
    "        ps = [p.clone().detach().requires_grad_() for p in self.Parameters()]\n",
    "         \n",
    "        return Normal(*ps)\n",
    "    \n",
    "    def log_prob(self, x):\n",
    "        \n",
    "        self.scale = torch.nn.functional.softplus(self.optim_scale)\n",
    "        \n",
    "        return super().log_prob(x)\n",
    "\n",
    "def push_addr(alpha, value):\n",
    "    return alpha + value\n",
    "\n",
    "def vector(*arg):\n",
    "    if len(arg) == 0:\n",
    "        return torch.tensor([])\n",
    "    # general case\n",
    "    try:\n",
    "        return torch.stack(arg, dim=0)\n",
    "    \n",
    "    # for concatenation of many vectors\n",
    "    except RuntimeError:\n",
    "        dim = len(arg[0].shape) - 1\n",
    "        return torch.cat(arg, dim=dim)\n",
    "    \n",
    "    # for distribution objects\n",
    "    except TypeError:\n",
    "        return list(arg)\n",
    "\n",
    "def get(v, i):\n",
    "    if type(i) is str:\n",
    "        return v[i]\n",
    "    return v[int(i.item())]\n",
    "\n",
    "def put(v, i, c):\n",
    "    if type(i) is str:\n",
    "        v[i] = c\n",
    "    else:\n",
    "        v[int(i.item())] = c\n",
    "    return v\n",
    "\n",
    "def first(v):\n",
    "    return v[0]\n",
    "\n",
    "def second(v):\n",
    "    return v[1]\n",
    "\n",
    "def last(v):\n",
    "    return v[-1]\n",
    "\n",
    "def append(v, c):\n",
    "    return torch.cat((v, c.unsqueeze(dim=0)), dim=0)\n",
    "\n",
    "def hashmap(*v):\n",
    "    hm = {}\n",
    "    i = 0\n",
    "    while i < len(v):\n",
    "        if type(v[i]) is str:\n",
    "            hm[v[i]] = v[i+1]\n",
    "        else:\n",
    "            hm[v[i].item()] = v[i+1]\n",
    "        i+=2\n",
    "    return hm\n",
    "\n",
    "def less_than(*args):\n",
    "    return args[0] < args[1]\n",
    "\n",
    "def rest(v):\n",
    "    return v[1:]\n",
    "\n",
    "def l(*arg):\n",
    "    return list(arg)\n",
    "\n",
    "def cons(x, l):\n",
    "    return [x] + l  \n",
    "\n",
    "def equal(x, y):\n",
    "    return torch.tensor(x.item() == y.item())\n",
    "\n",
    "def and_fn(x, y):\n",
    "    return x and y\n",
    "\n",
    "def or_fn(x, y):\n",
    "    return x or y\n",
    "\n",
    "def dirac(x):\n",
    "    # approximate with a normal distribution but with very small std\n",
    "    return torch.distributions.Normal(x, 0.001)\n",
    "\n",
    "def greater_than(x, y):\n",
    "    return x > y\n",
    "\n",
    "def empty(v):\n",
    "    return len(v) == 0\n",
    "\n",
    "def peek(v):\n",
    "    return v[-1]\n",
    "\n",
    "funcprimitives = {\n",
    "    \"vector\": vector,\n",
    "    \"get\": get,\n",
    "    \"put\": put,\n",
    "    \"first\": first,\n",
    "    \"last\": last,\n",
    "    \"append\": append,\n",
    "    \"hash-map\": hashmap,\n",
    "    \"less_than\": less_than,\n",
    "    \"second\": second,\n",
    "    \"rest\": rest,\n",
    "    \"conj\": append,\n",
    "    \"list\": l,\n",
    "    \"cons\": cons,\n",
    "    \"=\": equal,\n",
    "    \"and\": and_fn,\n",
    "    \"or\": or_fn,\n",
    "    \"dirac\": dirac,\n",
    "    \">\": greater_than,\n",
    "    \"empty?\": empty,\n",
    "    \"peek\": peek,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Env(dict):\n",
    "    \"An environment: a dict of {'var': val} pairs, with an outer Env.\"\n",
    "    def __init__(self, parms=(), args=(), outer=None):\n",
    "        self.update(zip(parms, args))\n",
    "        self.outer = outer\n",
    "    def find(self, var):\n",
    "        \"Find the innermost Env where var appears.\"\n",
    "        return self if (var in self) else self.outer.find(var)\n",
    "\n",
    "class Procedure(object):\n",
    "    \"A user-defined Scheme procedure.\"\n",
    "    def __init__(self, parms, body, env):\n",
    "        self.parms, self.body, self.env = parms, body, env\n",
    "    def __call__(self, *args): \n",
    "        print(\"BODY\", self.body)\n",
    "        return evaluate_helper(self.body, Env(self.parms, args, self.env))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-f4f7856a1269>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m \u001b[0mglobal_env\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstandard_env\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-f4f7856a1269>\u001b[0m in \u001b[0;36mstandard_env\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0menv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEnv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'alpha'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     env.update({'normal': dist.Normal,\n\u001b[0m\u001b[0;32m      6\u001b[0m        \u001b[1;34m'sqrt'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m        \u001b[1;34m'+'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dist' is not defined"
     ]
    }
   ],
   "source": [
    "def standard_env() -> Env:\n",
    "    \"An environment with some Scheme standard procedures.\"\n",
    "    env = Env()\n",
    "    env.update({'alpha' : ''}) \n",
    "    env.update({'normal': dist.Normal,\n",
    "       'sqrt': torch.sqrt,\n",
    "       '+': torch.add,\n",
    "       '-': torch.sub,\n",
    "       '*': torch.mul,\n",
    "       '/': torch.div,\n",
    "       'beta': dist.Beta,\n",
    "       'gamma': dist.Gamma,\n",
    "       'dirichlet': dist.Dirichlet,\n",
    "       'exponential': dist.Exponential,\n",
    "       'discrete': dist.Categorical,\n",
    "       'uniform': dist.Uniform,\n",
    "       'uniform-continuous': dist.Uniform,\n",
    "       'flip': dist.Bernoulli,\n",
    "       'vector': funcprimitives[\"vector\"],\n",
    "       'get': funcprimitives[\"get\"],\n",
    "       'put': funcprimitives[\"put\"],\n",
    "       'hash-map': funcprimitives[\"hash-map\"],\n",
    "       'first': funcprimitives[\"first\"],\n",
    "       'second': funcprimitives[\"second\"],\n",
    "       'last': funcprimitives[\"last\"],\n",
    "       'append': funcprimitives[\"append\"],\n",
    "       'conj': funcprimitives[\"conj\"],\n",
    "       'cons': funcprimitives[\"cons\"],\n",
    "       'list': funcprimitives[\"list\"],\n",
    "       '<': funcprimitives[\"less_than\"],\n",
    "       'mat-mul': torch.matmul,\n",
    "       'mat-repmat': lambda x, y, z: x.repeat((int(y.item()), int(z.item()))),\n",
    "       'mat-add': torch.add,\n",
    "       'mat-tanh': torch.tanh,\n",
    "       'mat-transpose': torch.t,\n",
    "       'rest': funcprimitives[\"rest\"],\n",
    "       '=' : funcprimitives[\"=\"],\n",
    "       '>': funcprimitives[\">\"],\n",
    "       'empty?': funcprimitives[\"empty?\"],\n",
    "       'log': torch.log,\n",
    "       'peek': funcprimitives['peek'],\n",
    "       })\n",
    "    return env\n",
    "\n",
    "global_env = standard_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_helper(x, env=global_env):\n",
    "    print(x, type(x))\n",
    "    try:\n",
    "        print(\"ENV OF VAR \", env.find('var'))\n",
    "        print()\n",
    "    except:\n",
    "        pass\n",
    "    \"Evaluate an expression in an environment.\"\n",
    "    if type(x) is str and x != 'fn':    # variable reference\n",
    "        try:\n",
    "            return env.find(x)[x]\n",
    "        except AttributeError:\n",
    "            return x\n",
    "    \n",
    "    elif type(x) in [int, float]: # constant \n",
    "        return torch.tensor(float(x))\n",
    "    \n",
    "    elif type(x) is torch.Tensor:\n",
    "        return x\n",
    "    \n",
    "    op, *args = x \n",
    "    \n",
    "    if op == 'if':             # conditional\n",
    "        (test, conseq, alt) = args\n",
    "        exp = (conseq if evaluate_helper(test, env) else alt)\n",
    "        return evaluate_helper(exp, env)\n",
    "            \n",
    "    elif op == 'fn':         # procedure\n",
    "        (parms, body) = args\n",
    "        \n",
    "        env_inner = Env(outer=env)\n",
    "        return Procedure(parms, body, env_inner)\n",
    "    \n",
    "    elif op == 'sample':\n",
    "        d = evaluate_helper(args[0], env)\n",
    "        return d.sample()\n",
    "    \n",
    "    elif op == 'observe':\n",
    "        return evaluate_helper(args[-1])\n",
    "\n",
    "    else:                        # procedure call\n",
    "        proc = evaluate_helper(op, env) \n",
    "        vals = [evaluate_helper(arg, env) for arg in args]  \n",
    "        return proc(*vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating\n",
    "i = 1\n",
    "exp = daphne(['desugar-hoppl', '-i', 'programs/hw5_{}.daphne'.format(i)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
